{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions, Optimizers, & The Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import gzip\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "from torch import tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(MNIST_URL = 'http://deeplearning.net/data/mnist/mnist.pkl'):\n",
    "    path = datasets.download_data(MNIST_URL, ext='.gz')\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        ((X_train, y_train), (X_val, y_val), _) = pickle.load(f, encoding='latin-1')\n",
    "    return map(tensor, (X_train, y_train, X_val, y_val))\n",
    "\n",
    "def normalize(x, m, s):\n",
    "    return (x-m)/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "    \u001b[0;32mdef\u001b[0m \u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkaiming_uniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mfan_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_fan_in_and_fan_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfan_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mbound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.nn.modules.conv._ConvNd.reset_parameters??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean, train_std = X_train.mean(), X_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = normalize(X_train, train_mean, train_std)\n",
    "X_test = normalize(X_test, train_mean, train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 1, 28, 28]), torch.Size([10000, 1, 28, 28]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.view(-1, 1, 28, 28)\n",
    "X_test = X_test.view(-1, 1, 28, 28)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, tensor(10))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = X_train.shape[0]\n",
    "c = y_test.max() + 1\n",
    "nh = 32\n",
    "n, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a `Conv2d` layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = nn.Conv2d(in_channels=1, out_channels=nh, kernel_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 1, 28, 28]), torch.Size([100]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = X_test[:100]\n",
    "y = y_test[:100]\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(x):\n",
    "    return x.mean(), x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor(0.0028, grad_fn=<MeanBackward0>),\n",
       "  tensor(0.1162, grad_fn=<StdBackward0>)),\n",
       " (tensor(-0.0055, grad_fn=<MeanBackward0>),\n",
       "  tensor(0.1096, grad_fn=<StdBackward0>)))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats(l1.weight), stats(l1.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = l1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0009, grad_fn=<MeanBackward0>),\n",
       " tensor(0.6126, grad_fn=<StdBackward0>))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like the outputs to have a mean of 0 and a standard deviation of 1. The mean is fine but the standard diviation is not quite there.\n",
    "\n",
    "Let's compare this to the normal Kaiming init with a leak of 1 because we're not using an activation function, remember:\n",
    "\n",
    "$$LeakyReLU(x,\\alpha)=\\begin{cases}\n",
    "x,  & \\text{if $x \\ge 0$} \\\\\n",
    "\\alpha x, & \\text{if $x < 0$}\n",
    "\\end{cases}$$\n",
    "\n",
    "When we switch to a normal kiming initialization with $a=1$, we get an output with $\\mu \\approx 0$ and $\\sigma \\approx 1$. So far so good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define `LeakyReLU` which defaults to `ReLU`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x, a=0):\n",
    "    return F.leaky_relu(l1(x), a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4653, grad_fn=<MeanBackward0>),\n",
       " tensor(0.8842, grad_fn=<StdBackward0>))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init.kaiming_normal_(l1.weight, a=0)\n",
    "stats(f1(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the relu function, the mean is no longer 0, it shifts to $\\approx 1/2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go back to look at how the `Conv2d` layer handle's it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = nn.Conv2d(1, nh, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2522, grad_fn=<MeanBackward0>),\n",
       " tensor(0.4492, grad_fn=<StdBackward0>))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats(f1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 5, 5])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_fs = l1.weight[0,0].numel()\n",
    "rec_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nf, ni, *_ = l1.weight.shape\n",
    "nf, ni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the number of projections (mappings) **in** and **out**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 800)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fan_in = ni * rec_fs\n",
    "fan_out = nf * rec_fs\n",
    "fan_in, fan_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain(a):\n",
    "    \"\"\"Calculates the gain for LeakyReLUs\"\"\"\n",
    "    return math.sqrt(2.0 / (1 + a**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0,\n",
       " 1.4142135623730951,\n",
       " 1.4141428569978354,\n",
       " 1.4071950894605838,\n",
       " 0.5773502691896257)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gain(1), gain(0), gain(0.01), gain(0.1), gain(math.sqrt(5.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing we should remember is that the PyTorch team uses Kaiming **uniform** and not Kaiming **normal**, which have different $\\sigma$ dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to know what is the standard deviation of a uniform distribution between $[-1,1]$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5810)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(10000).uniform_(-1, 1).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5773502691896258"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/math.sqrt(3.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the PyTorch team wanted the gain to handle uniform random numbers instead of settling on normal distributions (but still doesn't fully work).\n",
    "\n",
    "Let's implement our own version of kaiming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaiming2(x, a, use_fan_out=False):\n",
    "    nf, ni, *_ = x.shape\n",
    "    rec_fs = x[0,0].shape.numel()\n",
    "    fan = nf * rec_fs if use_fan_out else ni * rec_fs\n",
    "    std = gain(a) / math.sqrt(fan)\n",
    "    bound = math.sqrt(3.) * std\n",
    "    x.data.uniform_(-bound, bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5387, grad_fn=<MeanBackward0>),\n",
       " tensor(1.0285, grad_fn=<StdBackward0>))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaiming2(l1.weight, a=0);\n",
    "stats(f1(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is good, let's showcase what PyTorch's default does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2618, grad_fn=<MeanBackward0>),\n",
       " tensor(0.4266, grad_fn=<StdBackward0>))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaiming2(l1.weight, a=math.sqrt(5.));\n",
    "stats(f1(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at a final distribution's variance after multiple convolutional layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Sequential(\n",
    "    nn.Conv2d(1, 8, 5, stride=2, padding=2), nn.ReLU(),\n",
    "    nn.Conv2d(8, 16, 3, stride=2, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(16, 32, 3, stride=2, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(32, 1, 3, stride=2, padding=1),\n",
    "    nn.AdaptiveAvgPool2d(output_size=1),\n",
    "    Flatten(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0143, grad_fn=<MeanBackward0>),\n",
       " tensor(0.0079, grad_fn=<StdBackward0>))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = m(x)\n",
    "stats(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like a really big problem, the variance kept decrease from a standard deviation of 1 in the input layer to 0 in the final layer.\n",
    "\n",
    "Let's take a look at what happens for the loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(output, targ):\n",
    "    return (output.squeeze(-1) - targ).pow(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = mse(t, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0013), tensor(0.0248))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stats on the gradients\n",
    "stats(m[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now verify Kaiming uniform with $a=0$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkaiming_uniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fan_in'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnonlinearity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'leaky_relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0mkaiming_uniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fan_in'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonlinearity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'leaky_relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34mr\"\"\"Fills the input `Tensor` with values according to the method\u001b[0m\n",
       "\u001b[0;34m    described in `Delving deep into rectifiers: Surpassing human-level\u001b[0m\n",
       "\u001b[0;34m    performance on ImageNet classification` - He, K. et al. (2015), using a\u001b[0m\n",
       "\u001b[0;34m    uniform distribution. The resulting tensor will have values sampled from\u001b[0m\n",
       "\u001b[0;34m    :math:`\\mathcal{U}(-\\text{bound}, \\text{bound})` where\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    .. math::\u001b[0m\n",
       "\u001b[0;34m        \\text{bound} = \\sqrt{\\frac{6}{(1 + a^2) \\times \\text{fan\\_in}}}\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Also known as He initialization.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Args:\u001b[0m\n",
       "\u001b[0;34m        tensor: an n-dimensional `torch.Tensor`\u001b[0m\n",
       "\u001b[0;34m        a: the negative slope of the rectifier used after this layer (0 for ReLU\u001b[0m\n",
       "\u001b[0;34m            by default)\u001b[0m\n",
       "\u001b[0;34m        mode: either ``'fan_in'`` (default) or ``'fan_out'``. Choosing ``'fan_in'``\u001b[0m\n",
       "\u001b[0;34m            preserves the magnitude of the variance of the weights in the\u001b[0m\n",
       "\u001b[0;34m            forward pass. Choosing ``'fan_out'`` preserves the magnitudes in the\u001b[0m\n",
       "\u001b[0;34m            backwards pass.\u001b[0m\n",
       "\u001b[0;34m        nonlinearity: the non-linear function (`nn.functional` name),\u001b[0m\n",
       "\u001b[0;34m            recommended to use only with ``'relu'`` or ``'leaky_relu'`` (default).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Examples:\u001b[0m\n",
       "\u001b[0;34m        >>> w = torch.empty(3, 5)\u001b[0m\n",
       "\u001b[0;34m        >>> nn.init.kaiming_uniform_(w, mode='fan_in', nonlinearity='relu')\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_calculate_correct_fan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_gain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnonlinearity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgain\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstd\u001b[0m  \u001b[0;31m# Calculate uniform bounds from standard deviation\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/conda/lib/python3.7/site-packages/torch/nn/init.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "init.kaiming_uniform_??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in m:\n",
    "    if isinstance(l, nn.Conv2d):\n",
    "        init.kaiming_uniform_(l.weight)\n",
    "        l.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0115, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1828, grad_fn=<StdBackward0>))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = m(x)\n",
    "stats(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is better (after directly using `kaiming_uniform_` and not `reset_parameters`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = mse(t, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0076), tensor(0.2472))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stats on the gradients\n",
    "stats(m[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why you Need a Good Init\n",
    "\n",
    "To understand why initialization is so important, let's focus on the main NN operation: Matrix Multiplication.\n",
    "\n",
    "So let's just take a vector `x` and a matrix `a` and multiply them a 100 times (as if we had 100 layers):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(512)\n",
    "a = torch.randn(512, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    x = a @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(nan), tensor(nan))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mean(), x.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is activation explosion, we can even ask the loop to break when that happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(512)\n",
    "a = torch.randn(512, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    x = a @ x\n",
    "    if x.std() != x.std():\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, If you initialize your activations with a scale that is very low, you'll get another problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(512)\n",
    "a = torch.randn(512, 512) * 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    x = a @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(0.))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mean(), x.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is clear now, you can't really randomly initialize the weights of each layer, you have to be careful in the way you initialize them.\n",
    "\n",
    "People have came up with several ways to initialize their weight matrices, examples:\n",
    "\n",
    "- Use a standard deviation that makes sure that $X$ and $AX$ are exactly the same scale.\n",
    "- Use an orthogonal matrix to initialize the weights\n",
    "    - They preserve the $L_{2}$ norm\n",
    "        - $X$ and $AX$ would have the same sum of squares.\n",
    "- Use spectral normalization on the matrix A\n",
    "    - The spectral norm of $A$ is the least possible number $M$ such that: `torch.norm(A@X) <= M*torch.norm(X)`\n",
    "        - So dividing $A$ by $M$ insures you don't overflow.\n",
    "            - But you can still vanish with this.\n",
    ".. continue with the notebook from course-v3 if you're interested in initialization (Jeremy stops here).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchy.session_one import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = X_train.shape\n",
    "c = y_train.max() + 1\n",
    "nh = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(n_in=n, nh=nh, n_out=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Entropy Loss\n",
    "\n",
    "First we need to compute the softmax of our activations, defined by:\n",
    "\n",
    "$$softmax(x)_{i}=\\frac{e^{x_i}}{\\sum_{0 \\le j \\le n}e^{x_{j}}}$$\n",
    "\n",
    "In practice, wee need the log of the softmax to calculate the loss, because cross entropy is expressed as follows:\n",
    "\n",
    "$$J(\\Theta)=-\\sum_{i}y_{i}log(\\hat{p}_{i})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return (x.exp()/x.exp().sum(-1, keepdim=True)).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_pred = log_softmax(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But since our $y_{i}$ are one-hot encoded, this can be written as $-log(p_{i})$ where $i$ is the index of the desired target.\n",
    "\n",
    "Let's exploit a trick to avoid multiplying a bunch of zeros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.1744, grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred[0][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use advanced indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.1744, -2.2414, -2.4367], grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred[[0,1,2], [5,0,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(input, target):\n",
    "    return -input[range(target.shape[0]), target].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nll(sm_pred, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3159, grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's further simplify the `log_softmax` function using:\n",
    "\n",
    "$$log(\\frac{a}{b})=log(a)-log(b)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1, keepdim=True).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(nll(log_softmax(pred), y_train), loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The further you go away from zero, the less precise a computer will be, so let's use the `LogSumExp` Trick to get more stable output values:\n",
    "\n",
    "$$log(\\sum_{j=1}^{n}e^{x_j})=a+log(\\sum_{j=1}^{n}e^{x_{j}-a}); \\space a=max\\{x_{j}\\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp(x):\n",
    "    m = x.max(-1)[0]\n",
    "    return m + (x - m[:, None]).exp().sum(-1).log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way, we will avoid an overflow when taking the exponential of a big activation. In PyTorch, this is already implemented for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(logsumexp(pred), pred.logsumexp(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can use it for our softmax function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - x.logsumexp(-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(nll(log_softmax(pred), y_train), loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then use PyTorch's implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(F.nll_loss(F.log_softmax(pred, -1), y_train), loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch, `F.log_softmax` and `F.nll_loss` are combined in one optimized function, `F.cross_entropy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(F.cross_entropy(pred, y_train), loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb):\n",
    "    return (torch.argmax(out, dim=1) == yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.1050,  0.1474, -0.0562, -0.0702, -0.0886,  0.1723,  0.0840,  0.1594,\n",
       "         -0.1367,  0.0659], grad_fn=<SelectBackward>), torch.Size([64, 10]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 64\n",
    "xb = X_train[0:bs]  # A mini-batch from the training data set\n",
    "preds = model(xb)\n",
    "preds[0], preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3190, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb = y_train[0:bs]\n",
    "loss_func(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1250)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1  # learning rate\n",
    "epochs = 5  # how many epochs to train for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)//bs + 1):  # a mini-batch at a time.\n",
    "        start_i = i * bs\n",
    "        end_i = start_i + bs\n",
    "        xb = X_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        loss = loss_func(model(xb), yb)\n",
    "        \n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            for l in model.layers:\n",
    "                if hasattr(l, 'weight'):\n",
    "                    l.weight -= l.weight.grad * lr\n",
    "                    l.bias -= l.bias.grad * lr\n",
    "                    l.weight.grad.zero_()\n",
    "                    l.bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9089, grad_fn=<NllLossBackward>), tensor(0.7748))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(model(X_train), y_train), accuracy(model(X_train), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using parameters & optim\n",
    "\n",
    "#### Parameters\n",
    "\n",
    "Use `nn.Module.__setattr__` and move `relu` to functional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_in, nh)\n",
    "        self.l2 = nn.Linear(nh, n_out)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.l2(F.relu(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(n_in=n, nh=nh, n_out=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1: Linear(in_features=784, out_features=50, bias=True)\n",
      "l2: Linear(in_features=50, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for name, layer in model.named_children():\n",
    "    print(f'{name}: {layer}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=784, out_features=50, bias=True)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.l1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reduce our training loop using PyTorch inner parameter updates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range((n-1)//bs + 1):\n",
    "            start_i = i * bs\n",
    "            end_i = start_i + bs\n",
    "            xb = X_train[start_i:end_i]\n",
    "            yb = y_train[start_i:end_i]\n",
    "            loss = loss_func(model(xb), yb)\n",
    "\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters(): p -= p.grad * lr\n",
    "                model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6347, grad_fn=<NllLossBackward>), tensor(0.8906))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Registering Modules\n",
    "\n",
    "We can use the original `layers` approach, but we have to register the modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            self.add_module(f'layer_{i}', layer)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layer_0): Linear(in_features=50000, out_features=50, bias=True)\n",
       "  (layer_1): ReLU()\n",
       "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this is kind of clunky so let's use `nn.ModuleList`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.ModuleList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialModel(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialModel(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=50000, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SequentialModel(layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also is a bit clunky, and surprisingly, we have `nn.Sequential`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(n, nh), nn.ReLU(), nn.Linear(nh, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6586, grad_fn=<NllLossBackward>), tensor(0.8438))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m        \n",
       "\u001b[0;32mclass\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34mr\"\"\"A sequential container.\u001b[0m\n",
       "\u001b[0;34m    Modules will be added to it in the order they are passed in the constructor.\u001b[0m\n",
       "\u001b[0;34m    Alternatively, an ordered dict of modules can also be passed in.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    To make it easier to understand, here is a small example::\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        # Example of using Sequential\u001b[0m\n",
       "\u001b[0;34m        model = nn.Sequential(\u001b[0m\n",
       "\u001b[0;34m                  nn.Conv2d(1,20,5),\u001b[0m\n",
       "\u001b[0;34m                  nn.ReLU(),\u001b[0m\n",
       "\u001b[0;34m                  nn.Conv2d(20,64,5),\u001b[0m\n",
       "\u001b[0;34m                  nn.ReLU()\u001b[0m\n",
       "\u001b[0;34m                )\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        # Example of using Sequential with OrderedDict\u001b[0m\n",
       "\u001b[0;34m        model = nn.Sequential(OrderedDict([\u001b[0m\n",
       "\u001b[0;34m                  ('conv1', nn.Conv2d(1,20,5)),\u001b[0m\n",
       "\u001b[0;34m                  ('relu1', nn.ReLU()),\u001b[0m\n",
       "\u001b[0;34m                  ('conv2', nn.Conv2d(20,64,5)),\u001b[0m\n",
       "\u001b[0;34m                  ('relu2', nn.ReLU())\u001b[0m\n",
       "\u001b[0;34m                ]))\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_get_item_by_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Get the idx-th item of the iterator\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index {} is out of range'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0midx\u001b[0m \u001b[0;34m%=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_by_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_by_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__delitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mdelattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_by_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdelattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m           /opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     ConvReLU2d, LinearReLU, ConvBn2d, ConvBnReLU2d\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn.Sequential??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optim\n",
    "\n",
    "Let's replace our previously manually coded optimization step, and instead use just:\n",
    "\n",
    "```Python\n",
    "opt.step()\n",
    "opt.zero_grad()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer():\n",
    "    def __init__(self, params, lr):\n",
    "        self.params, self.lr = list(params), lr\n",
    "    \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params:\n",
    "                p -= lr * p.grad\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for p in self.params:\n",
    "            p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(n, nh), nn.ReLU(), nn.Linear(nh, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Optimizer(model.parameters(), lr=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)//bs + 1):\n",
    "        start_i = i * bs\n",
    "        end_i = start_i + bs\n",
    "        xb = X_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        loss = loss_func(model(xb), yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6739, grad_fn=<NllLossBackward>), tensor(0.8906))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch already provides this exact functionality in `optim.SGD`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "    \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Performs a single optimization step.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Arguments:\u001b[0m\n",
       "\u001b[0;34m            closure (callable, optional): A closure that reevaluates the model\u001b[0m\n",
       "\u001b[0;34m                and returns the loss.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mweight_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmomentum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'momentum'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdampening\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dampening'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mnesterov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nesterov'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0md_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mparam_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;32mif\u001b[0m \u001b[0;34m'momentum_buffer'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                        \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'momentum_buffer'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                        \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'momentum_buffer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                        \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdampening\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                        \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                        \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/conda/lib/python3.7/site-packages/torch/optim/sgd.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optim.SGD.step??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we remove all of the other options, we end up with the same formulation we implemented earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = nn.Sequential(nn.Linear(n, nh), nn.ReLU(), nn.Linear(nh, 10))\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3197, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)//bs + 1):\n",
    "        start_i = i * bs\n",
    "        end_i = start_i + bs\n",
    "        xb = X_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        loss = loss_func(model(xb), yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6604, grad_fn=<NllLossBackward>), tensor(0.8750))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomized tests can be very useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert acc>0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Never fix the random seed until you finish all your experiments and you want a reproducibility state. You do this because It's beneficial for you to notice the variability within you model/generators/.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset & DataLoader\n",
    "\n",
    "### Dataset\n",
    "\n",
    "It's clunky to iterate over X,y mini-batche values separately. Instead let's do these two steps together, introducing the `Dataset` class: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds = Dataset(X_train, y_train), Dataset(X_val, y_val)\n",
    "assert len(train_ds) == len(X_train)\n",
    "assert len(valid_ds) == len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = train_ds[0:5]\n",
    "assert xb.shape == (5, 28*28)\n",
    "assert yb.shape == (5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)//bs + 1):\n",
    "        xb, yb = train_ds[i*bs:i*bs+bs]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.7124, grad_fn=<NllLossBackward>), tensor(0.9219))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader\n",
    "\n",
    "Let's make the way we loop much cleaner, using the DataLoader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, ds, bs):\n",
    "        self.ds, self.bs = ds, bs\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self.ds), self.bs):\n",
    "            yield self.ds[i:i+self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs)\n",
    "val_dl = DataLoader(valid_ds, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = next(iter(val_dl))\n",
    "assert xb.shape==(bs, 28*28)\n",
    "assert yb.shape==(bs,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xb[0].view(28,28), cmap='gray')\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs=1):\n",
    "    for epoch in range(epochs):\n",
    "        for xb, yb in train_dl:\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2799, grad_fn=<NllLossBackward>), tensor(0.9375))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert acc > 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code in a way that you can read and understand the final version in simple english."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Shuffling\n",
    "\n",
    "We want our training set to be in random order, and that order should differ at each iteration. But the validation set shouldn't be randomized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler():\n",
    "    def __init__(self, ds, bs, shuffle=False):\n",
    "        self.m, self.bs, self.shuffle = len(ds), bs, shuffle\n",
    "    \n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            self.idxs = torch.randperm(self.m)\n",
    "        else:\n",
    "            self.idxs = torch.arange(self.m)\n",
    "        for i in range(0, self.m, self.bs):\n",
    "            yield self.idxs[i:i+self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_ds = Dataset(*train_ds[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Sampler(small_ds, 3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([7, 8, 2]), tensor([0, 5, 4]), tensor([6, 3, 9]), tensor([1])]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[o for o in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Sampler(small_ds, 3, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0, 1, 2]), tensor([3, 4, 5]), tensor([6, 7, 8]), tensor([9])]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[o for o in s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the sampler in our data loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(b):\n",
    "    xs, ys = zip(*b)\n",
    "    return torch.stack(xs), torch.stack(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, ds, sampler, collate_fn=collate):\n",
    "        self.ds, self.sampler, self.collate_fn = ds, sampler, collate_fn\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for s in self.sampler:\n",
    "            yield self.collate_fn([self.ds[i] for i in s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the new samplers and dataloaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samp = Sampler(train_ds, bs=bs, shuffle=True)\n",
    "valid_samp = Sampler(valid_ds, bs=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, sampler=train_samp, collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, sampler=valid_samp, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = next(iter(valid_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xb[0].reshape(28,28), cmap='gray')\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAANX0lEQVR4nO3dYagd9ZnH8d9PTRGSKlFRL6msTYnosmi6RL1qWbLUFDe+iIIpCbhmWSEVGmhFZKULNrAERbZdjC8KtxibXbrGgqmGoraXUHT1ReNVY4yNabIh294mJGrEWoVkkzz74k7ca7wz5+bMmTMneb4fOJxz5jkz83C4vztzzsycvyNCAM58Z7XdAID+IOxAEoQdSIKwA0kQdiCJc/q5Mtt89Q80LCI81fRaW3bbt9jeaXu37QfqLAtAs9ztcXbbZ0v6naRFksYlvSppeUT8tmIetuxAw5rYsl8naXdE7ImII5I2SFpSY3kAGlQn7HMk/WHS8/Fi2mfYXml7zPZYjXUBqKnOF3RT7Sp8bjc9IkYkjUjsxgNtqrNlH5d02aTnX5K0r147AJpSJ+yvSppn+8u2vyBpmaRNvWkLQK91vRsfEUdtr5L0S0lnS1oXEW/3rDMAPdX1obeuVsZndqBxjZxUA+D0QdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEn0dsnmQPfTQQ5X1mTNnltbuvPPOynkPHDhQWb/yyisr601au3ZtZX10dLSy/uKLL1bWDx8+XFo7cuRI5bzoLbbsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEo7gW7rvvvsr66tWrS2tVx+DPdPaUA4Z+6rnnniutLV26tHLeTz75pKuesisbxbXWSTW290r6SNIxSUcjYkGd5QFoTi/OoPvbiHivB8sB0CA+swNJ1A17SPqV7ddsr5zqBbZX2h6zPVZzXQBqqLsbf1NE7LN9saRR2+9ExEuTXxARI5JGpMH+gg4409XaskfEvuL+oKSfS7quF00B6L2uw257pu0vnngs6RuStveqMQC91fVxdttzNbE1lyY+DvxnRKzpMM9puxs/PDxcWmvzevS6rr322sr6okWLKuvz5s2rrFf9fW3cuLFy3jvuuKOyjqn1/Dh7ROyRdE3XHQHoKw69AUkQdiAJwg4kQdiBJAg7kASXuKKW5cuXV9YfffTR0tq5555bOe9dd91VWX/mmWcq61mVHXpjyw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSXCcHY2qGhJ61apVlfPu2rWrsn7DDTdU1g8dOlRZP1NxnB1IjrADSRB2IAnCDiRB2IEkCDuQBGEHkuA4Oxq1YEH5wL5btmyptezFixdX1l944YVayz9dcZwdSI6wA0kQdiAJwg4kQdiBJAg7kARhB5LoehRXYDp27txZWtu2bVvlvFdffXWv20mt45bd9jrbB21vnzTtAtujtncV97ObbRNAXdPZjf+JpFtOmvaApM0RMU/S5uI5gAHWMewR8ZKkk3/fZ4mk9cXj9ZJu63FfAHqs28/sl0TEfkmKiP22Ly57oe2VklZ2uR4APdL4F3QRMSJpROJCGKBN3R56O2B7SJKK+4O9awlAE7oN+yZJK4rHKyQ925t2ADSl42687SclLZR0ke1xSd+X9LCkn9m+W9LvJS1tskmcvm688cbSGsfR+6tj2CNieUnp6z3uBUCDOF0WSIKwA0kQdiAJwg4kQdiBJLjEFY269dZb224BBbbsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEQzajllmzZlXWDx06+ecL/98551Sf5tHpp6arhoOWpKNHj1bWz1QM2QwkR9iBJAg7kARhB5Ig7EAShB1IgrADSXA9O2oZHR2trM+YMaO09v7771fOu2zZssp61uPo3WLLDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJcJwdlW6//fbK+vDwcGX92LFjpbUnnniict533nmnso5T03HLbnud7YO2t0+attr2H21vLW6Lm20TQF3T2Y3/iaRbppj+bxExv7g919u2APRax7BHxEuSyn9bCMBpoc4XdKtsbyt282eXvcj2SttjtsdqrAtATd2G/UeSviJpvqT9kn5Q9sKIGImIBRFR/euAABrVVdgj4kBEHIuI45J+LOm63rYFoNe6CrvtoUlPb5e0vey1AAZDx+Pstp+UtFDSRbbHJX1f0kLb8yWFpL2SvtVgj6jhvPPOq6x3Gj99/fr1tda/bt260tr9999fa9k4NR3DHhHLp5j8eAO9AGgQp8sCSRB2IAnCDiRB2IEkCDuQBJe4ngFmzy49W1lPPfVU5bw333xzrXVv2bKlsv7II4/UWn5bLr300sp61aW7kjRnzpzK+tatW0+5p7rYsgNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEo6I/q3M7t/KziCdfs75wQcfLK1dc801vW7nMxYuXFhZP378eGntwgsvrJz3nnvu6aalnpg7d25lvdNw0VdddVVl/ayzmtvORoSnXGdjawQwUAg7kARhB5Ig7EAShB1IgrADSRB2IAmOs/dBp59zfuyxxyrrS5YsqbX8JtlTHtL9VD//vk727rvvltbGxuqNRtZp/tHR0cr6yy+/XGv9VTjODiRH2IEkCDuQBGEHkiDsQBKEHUiCsANJ8Lvx0zR//vzS2vXXX18577333ltZv+KKK7rq6XTwxhtvlNZ2795da9kbNmyorL/55pultT179tRa9+mo45bd9mW2f217h+23bX+nmH6B7VHbu4r78pEKALRuOrvxRyXdFxFXSRqW9G3bfynpAUmbI2KepM3FcwADqmPYI2J/RLxePP5I0g5JcyQtkbS+eNl6Sbc11SSA+k7pM7vtyyV9VdJvJF0SEfuliX8Iti8umWelpJX12gRQ17TDbnuWpKclfTci/tTpAogTImJE0kixjJQXwgCDYFqH3mzP0ETQfxoRG4vJB2wPFfUhSQebaRFAL3TcsntiE/64pB0R8cNJpU2SVkh6uLh/tpEO+2R4eLiy/vzzz5fWzj///F638xnj4+OV9U6XU1ZZu3ZtZf3jjz/uetlS9WWmH374Ya1l49RMZzf+Jkl/L+kt2ycGlf6eJkL+M9t3S/q9pKXNtAigFzqGPSJellT2Af3rvW0HQFM4XRZIgrADSRB2IAnCDiRB2IEkuMS1MDQ0VFmvcyy96hi9JK1Zs6ayvmPHjsr6Bx98cMo9IR+27EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBEM2Fzr98s6iRYtKa6+88krlvIcPH66sHz16tLIOnAqGbAaSI+xAEoQdSIKwA0kQdiAJwg4kQdiBJDjODpxhOM4OJEfYgSQIO5AEYQeSIOxAEoQdSIKwA0l0DLvty2z/2vYO22/b/k4xfbXtP9reWtwWN98ugG51PKnG9pCkoYh43fYXJb0m6TZJ35T054j412mvjJNqgMaVnVQznfHZ90vaXzz+yPYOSXN62x6App3SZ3bbl0v6qqTfFJNW2d5me53t2SXzrLQ9ZnusVqcAapn2ufG2Z0l6UdKaiNho+xJJ70kKSf+iiV39f+ywDHbjgYaV7cZPK+y2Z0j6haRfRsQPp6hfLukXEfFXHZZD2IGGdX0hjCd+dvVxSTsmB7344u6E2yVtr9skgOZM59v4r0n6L0lvSTpeTP6epOWS5mtiN36vpG8VX+ZVLYstO9CwWrvxvULYgeZxPTuQHGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJjj842WPvSfqfSc8vKqYNokHtbVD7kuitW73s7S/KCn29nv1zK7fHImJBaw1UGNTeBrUvid661a/e2I0HkiDsQBJth32k5fVXGdTeBrUvid661ZfeWv3MDqB/2t6yA+gTwg4k0UrYbd9ie6ft3bYfaKOHMrb32n6rGIa61fHpijH0DtrePmnaBbZHbe8q7qccY6+l3gZiGO+KYcZbfe/aHv6875/ZbZ8t6XeSFkkal/SqpOUR8du+NlLC9l5JCyKi9RMwbP+NpD9L+vcTQ2vZfkTSoYh4uPhHOTsi/mlAelutUxzGu6HeyoYZ/we1+N71cvjzbrSxZb9O0u6I2BMRRyRtkLSkhT4GXkS8JOnQSZOXSFpfPF6viT+WvivpbSBExP6IeL14/JGkE8OMt/reVfTVF22EfY6kP0x6Pq7BGu89JP3K9mu2V7bdzBQuOTHMVnF/ccv9nKzjMN79dNIw4wPz3nUz/HldbYR9qqFpBun4300R8deS/k7St4vdVUzPjyR9RRNjAO6X9IM2mymGGX9a0ncj4k9t9jLZFH315X1rI+zjki6b9PxLkva10MeUImJfcX9Q0s818bFjkBw4MYJucX+w5X4+FREHIuJYRByX9GO1+N4Vw4w/LemnEbGxmNz6ezdVX/1639oI+6uS5tn+su0vSFomaVMLfXyO7ZnFFyeyPVPSNzR4Q1FvkrSieLxC0rMt9vIZgzKMd9kw42r5vWt9+POI6PtN0mJNfCP/35L+uY0eSvqaK+nN4vZ2271JelITu3X/q4k9orslXShps6Rdxf0FA9Tbf2hiaO9tmgjWUEu9fU0THw23Sdpa3Ba3/d5V9NWX943TZYEkOIMOSIKwA0kQdiAJwg4kQdiBJAg7kARhB5L4P+5WOja7CmZDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xb[0].reshape(28,28), cmap='gray')\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()\n",
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2441, grad_fn=<NllLossBackward>), tensor(0.9219))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert acc > 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, sampler=RandomSampler(train_ds), collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, sampler=SequentialSampler(valid_ds), collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = next(iter(valid_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xb[0].reshape(28,28), cmap='gray')\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xb[0].reshape(28,28), cmap='gray')\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0014, grad_fn=<NllLossBackward>), tensor(1.))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert acc > 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch defaults work fine for most things however:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs, shuffle=True, drop_last=True)\n",
    "valid_dl = DataLoader(valid_ds, bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0553, grad_fn=<NllLossBackward>), tensor(1.))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert acc > 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for the PyTorch `DataLoader`, if you pass `num_workers`, it will use multiple threads to call your `Dataset`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "\n",
    "You should always have a validation set in order to know if you are overfitting.\n",
    "\n",
    "We will calculate and print the validation loss at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, loss_func, opt, train_dl, val_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # to activate layers like batchNorm and Dropout\n",
    "        for xb, yb in train_dl:\n",
    "            loss = loss_func(model(xb), yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            tot_loss, tot_acc = 0., 0.\n",
    "            for xb, yb in val_dl:\n",
    "                pred = model(xb)\n",
    "                tot_loss += loss_func(pred, yb)\n",
    "                tot_acc += accuracy(pred, yb)\n",
    "        nv = len(valid_dl)\n",
    "        print(epoch, tot_loss/nv, tot_acc/nv)\n",
    "    return tot_loss/nv, tot_acc/nv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
    "    \"\"\"Returns the dataloaders for both the training and validation sets\"\"\"\n",
    "    return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n",
    "            DataLoader(valid_ds, batch_size=bs*2, **kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the whole process of getting the data loader and training the model can be done in 3 lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, valid_dl = get_dls(train_ds, valid_ds, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.2863) tensor(0.9167)\n"
     ]
    }
   ],
   "source": [
    "loss, acc = fit(1, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert acc > 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infinitely Customizable Training Loops\n",
    "\n",
    "- Usually, we write a new training loop for every task.\n",
    "- Or try to write something that incorporate everything you can think of.\n",
    "- Fortunately, there is a way around this: **Callbacks**\n",
    "- It's then easy to mix and match these blocks together.\n",
    "    - `fastai` uses callbacks to structure new compute blocks and incorporate them in architectures and algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataBunch/Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds = Dataset(X_train, y_train), Dataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh, bs = 50, 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = y_train.max().item() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of benefits of packaging stuff together and a function shouldn't have a lot of parameters.\n",
    "\n",
    "Here is the signature of the fit function:\n",
    "\n",
    "```Python\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)\n",
    "```\n",
    "\n",
    "Conceptually, `train_dl` & `valid_dl` should be together, then everything except `epochs` should be together into `Learner`, let's start with what we call a `DataBunch`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataBunch():\n",
    "    def __init__(self, train_dl, val_dl, c=None):\n",
    "        self.train_dl, self.val_dl, self.c = train_dl, val_dl, c\n",
    "    \n",
    "    @property\n",
    "    def train_ds(self):\n",
    "        return self.train_dl.dataset\n",
    "    \n",
    "    @property\n",
    "    def valid_ds(self):\n",
    "        return self.val_dl.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch(*get_dls(train_ds, val_ds, bs), c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(data, lr=0.5, nh=50):\n",
    "    n = data.train_ds.x.shape[1]\n",
    "    model = nn.Sequential(nn.Linear(n, nh), nn.ReLU(), nn.Linear(nh, data.c))\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner():\n",
    "    def __init__(self, model, opt, loss_func, data):\n",
    "        self.model, self.opt, self.loss_func, self.data = model, opt, loss_func, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(*get_model(data), loss_func, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inject the learner into the fit function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, learn):\n",
    "    for epoch in range(epochs):\n",
    "        learn.model.train()\n",
    "        for xb, yb in learn.data.train_dl:\n",
    "            loss = learn.loss_func(learn.model(xb), yb)\n",
    "            loss.backward()\n",
    "            learn.opt.step()\n",
    "            learn.opt.zero_grad()\n",
    "        \n",
    "        learn.model.eval()\n",
    "        with torch.no_grad():\n",
    "            tot_loss, tot_acc = 0., 0.\n",
    "            for xb, yb in learn.data.val_dl:\n",
    "                pred = learn.model(xb)\n",
    "                tot_loss += learn.loss_func(pred, yb)\n",
    "                tot_acc += accuracy(pred, yb)\n",
    "        nv = len(learn.data.val_dl)\n",
    "        print(epoch, tot_loss/nv, tot_acc/nv)\n",
    "    return tot_loss/nv, tot_acc/nv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.1930) tensor(0.9409)\n",
      "1 tensor(0.1422) tensor(0.9591)\n",
      "2 tensor(0.1444) tensor(0.9610)\n",
      "3 tensor(0.1209) tensor(0.9658)\n",
      "4 tensor(0.1582) tensor(0.9541)\n"
     ]
    }
   ],
   "source": [
    "loss, acc = fit(5, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CallBackHandler\n",
    "\n",
    "We will add a callback to remove complexity from loop, and make it flexible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_batch(xb, yb, cb):\n",
    "    if not cb.begin_batch(xb,yb): \n",
    "        return\n",
    "    loss = cb.learn.loss_func(cb.learn.model(xb), yb)\n",
    "    if not cb.after_loss(loss): \n",
    "        return\n",
    "    loss.backward()\n",
    "    if cb.after_backward(): \n",
    "        cb.learn.opt.step()\n",
    "    if cb.after_step(): \n",
    "        cb.learn.opt.zero_grad()\n",
    "\n",
    "def all_batches(dl, cb):\n",
    "    for xb,yb in dl:\n",
    "        one_batch(xb, yb, cb)\n",
    "        if cb.do_stop(): return\n",
    "\n",
    "def fit(epochs, learn, cb):\n",
    "    if not cb.begin_fit(learn): \n",
    "        return\n",
    "    for epoch in range(epochs):\n",
    "        if not cb.begin_epoch(epoch): \n",
    "            continue\n",
    "        all_batches(learn.data.train_dl, cb)\n",
    "        \n",
    "        if cb.begin_validate():\n",
    "            with torch.no_grad(): \n",
    "                all_batches(learn.data.val_dl, cb)\n",
    "        if cb.do_stop() or not cb.after_epoch(): \n",
    "            break\n",
    "    cb.after_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callback():\n",
    "    \n",
    "    def begin_fit(self, learn):\n",
    "        self.learn = learn\n",
    "        return True\n",
    "    \n",
    "    def after_fit(self): \n",
    "        return True\n",
    "    \n",
    "    def begin_epoch(self, epoch):\n",
    "        self.epoch=epoch\n",
    "        return True\n",
    "    \n",
    "    def begin_validate(self): \n",
    "        return True\n",
    "   \n",
    "    def after_epoch(self): \n",
    "        return True\n",
    "    \n",
    "    def begin_batch(self, xb, yb):\n",
    "        self.xb,self.yb = xb,yb\n",
    "        return True\n",
    "    \n",
    "    def after_loss(self, loss):\n",
    "        self.loss = loss\n",
    "        return True\n",
    "    \n",
    "    def after_backward(self): \n",
    "        return True\n",
    "    \n",
    "    def after_step(self): \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CallbackHandler():\n",
    "    def __init__(self,cbs=None):\n",
    "        self.cbs = cbs if cbs else []\n",
    "\n",
    "    def begin_fit(self, learn):\n",
    "        self.learn,self.in_train = learn,True\n",
    "        learn.stop = False\n",
    "        res = True\n",
    "        for cb in self.cbs: res = res and cb.begin_fit(learn)\n",
    "        return res\n",
    "\n",
    "    def after_fit(self):\n",
    "        res = not self.in_train\n",
    "        for cb in self.cbs: res = res and cb.after_fit()\n",
    "        return res\n",
    "    \n",
    "    def begin_epoch(self, epoch):\n",
    "        self.learn.model.train()\n",
    "        self.in_train=True\n",
    "        res = True\n",
    "        for cb in self.cbs: res = res and cb.begin_epoch(epoch)\n",
    "        return res\n",
    "    \n",
    "    def begin_validate(self):\n",
    "        self.learn.model.eval()\n",
    "        self.in_train=False\n",
    "        res = True\n",
    "        for cb in self.cbs: res = res and cb.begin_validate()\n",
    "        return res\n",
    "\n",
    "    def after_epoch(self):\n",
    "        res = True\n",
    "        for cb in self.cbs: res = res and cb.after_epoch()\n",
    "        return res\n",
    "    \n",
    "    def begin_batch(self, xb, yb):\n",
    "        res = True\n",
    "        for cb in self.cbs: res = res and cb.begin_batch(xb, yb)\n",
    "        return res\n",
    "\n",
    "    def after_loss(self, loss):\n",
    "        res = self.in_train\n",
    "        for cb in self.cbs: res = res and cb.after_loss(loss)\n",
    "        return res\n",
    "\n",
    "    def after_backward(self):\n",
    "        res = True\n",
    "        for cb in self.cbs: res = res and cb.after_backward()\n",
    "        return res\n",
    "\n",
    "    def after_step(self):\n",
    "        res = True\n",
    "        for cb in self.cbs: res = res and cb.after_step()\n",
    "        return res\n",
    "    \n",
    "    def do_stop(self):\n",
    "        try:     return self.learn.stop\n",
    "        finally: self.learn.stop = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCallback(Callback):\n",
    "    def begin_fit(self,learn):\n",
    "        super().begin_fit(learn)\n",
    "        self.n_iters = 0\n",
    "        return True\n",
    "        \n",
    "    def after_step(self):\n",
    "        self.n_iters += 1\n",
    "        print(self.n_iters)\n",
    "        if self.n_iters>=10: self.learn.stop = True\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "fit(1, learn, cb=CallbackHandler([TestCallback()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Runner` is an attempt to repackage the above:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "_camel_re1 = re.compile('(.)([A-Z][a-z]+)')\n",
    "_camel_re2 = re.compile('([a-z0-9])([A-Z])')\n",
    "def camel2snake(name):\n",
    "    s1 = re.sub(_camel_re1, r'\\1_\\2', name)\n",
    "    return re.sub(_camel_re2, r'\\1_\\2', s1).lower()\n",
    "\n",
    "class Callback():\n",
    "    _order=0\n",
    "    def set_runner(self, run): self.run=run\n",
    "    def __getattr__(self, k): return getattr(self.run, k)\n",
    "    @property\n",
    "    def name(self):\n",
    "        name = re.sub(r'Callback$', '', self.__class__.__name__)\n",
    "        return camel2snake(name or 'callback')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainEvalCallback(Callback):\n",
    "    def begin_fit(self):\n",
    "        self.run.n_epochs=0.\n",
    "        self.run.n_iter=0\n",
    "    \n",
    "    def after_batch(self):\n",
    "        if not self.in_train: return\n",
    "        self.run.n_epochs += 1./self.iters\n",
    "        self.run.n_iter   += 1\n",
    "        \n",
    "    def begin_epoch(self):\n",
    "        self.run.n_epochs=self.epoch\n",
    "        self.model.train()\n",
    "        self.run.in_train=True\n",
    "\n",
    "    def begin_validate(self):\n",
    "        self.model.eval()\n",
    "        self.run.in_train=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-create our test callback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCallback(Callback):\n",
    "    def after_step(self):\n",
    "        if self.train_eval.n_iters>=10: return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_eval_callback'"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbname = 'TrainEvalCallback'\n",
    "camel2snake(cbname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_eval'"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainEvalCallback().name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "\n",
    "def listify(o):\n",
    "    if o is None: return []\n",
    "    if isinstance(o, list): return o\n",
    "    if isinstance(o, str): return [o]\n",
    "    if isinstance(o, Iterable): return list(o)\n",
    "    return [o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runner():\n",
    "    def __init__(self, cbs=None, cb_funcs=None):\n",
    "        cbs = listify(cbs)\n",
    "        for cbf in listify(cb_funcs):\n",
    "            cb = cbf()\n",
    "            setattr(self, cb.name, cb)\n",
    "            cbs.append(cb)\n",
    "        self.stop,self.cbs = False,[TrainEvalCallback()]+cbs\n",
    "\n",
    "    @property\n",
    "    def opt(self):       return self.learn.opt\n",
    "    @property\n",
    "    def model(self):     return self.learn.model\n",
    "    @property\n",
    "    def loss_func(self): return self.learn.loss_func\n",
    "    @property\n",
    "    def data(self):      return self.learn.data\n",
    "\n",
    "    def one_batch(self, xb, yb):\n",
    "        self.xb,self.yb = xb,yb\n",
    "        if self('begin_batch'): return\n",
    "        self.pred = self.model(self.xb)\n",
    "        if self('after_pred'): return\n",
    "        self.loss = self.loss_func(self.pred, self.yb)\n",
    "        if self('after_loss') or not self.in_train: return\n",
    "        self.loss.backward()\n",
    "        if self('after_backward'): return\n",
    "        self.opt.step()\n",
    "        if self('after_step'): return\n",
    "        self.opt.zero_grad()\n",
    "\n",
    "    def all_batches(self, dl):\n",
    "        self.iters = len(dl)\n",
    "        for xb,yb in dl:\n",
    "            if self.stop: break\n",
    "            self.one_batch(xb, yb)\n",
    "            self('after_batch')\n",
    "        self.stop=False\n",
    "        \n",
    "    def fit(self, epochs, learn):\n",
    "        self.epochs,self.learn = epochs,learn\n",
    "\n",
    "        try:\n",
    "            for cb in self.cbs: cb.set_runner(self)\n",
    "            if self('begin_fit'): return\n",
    "            for epoch in range(epochs):\n",
    "                self.epoch = epoch\n",
    "                if not self('begin_epoch'): self.all_batches(self.data.train_dl)\n",
    "\n",
    "                with torch.no_grad(): \n",
    "                    if not self('begin_validate'): self.all_batches(self.data.val_dl)\n",
    "                if self('after_epoch'): break\n",
    "            \n",
    "        finally:\n",
    "            self('after_fit')\n",
    "            self.learn = None\n",
    "\n",
    "    def __call__(self, cb_name):\n",
    "        for cb in sorted(self.cbs, key=lambda x: x._order):\n",
    "            f = getattr(cb, cb_name, None)\n",
    "            if f and f(): return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to compute metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AvgStats():\n",
    "    def __init__(self, metrics, in_train): \n",
    "        self.metrics, self.in_train = listify(metrics), in_train\n",
    "    \n",
    "    def reset(self):\n",
    "        self.tot_loss,self.count = 0.,0\n",
    "        self.tot_mets = [0.] * len(self.metrics)\n",
    "        \n",
    "    @property\n",
    "    def all_stats(self): \n",
    "        return [self.tot_loss.item()] + self.tot_mets\n",
    "    \n",
    "    @property\n",
    "    def avg_stats(self): \n",
    "        return [o/self.count for o in self.all_stats]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        if not self.count: return \"\"\n",
    "        return f\"{'train' if self.in_train else 'valid'}: {self.avg_stats}\"\n",
    "\n",
    "    def accumulate(self, run):\n",
    "        bn = run.xb.shape[0]\n",
    "        self.tot_loss += run.loss * bn\n",
    "        self.count += bn\n",
    "        for i,m in enumerate(self.metrics):\n",
    "            self.tot_mets[i] += m(run.pred, run.yb) * bn\n",
    "\n",
    "class AvgStatsCallback(Callback):\n",
    "    def __init__(self, metrics):\n",
    "        self.train_stats,self.valid_stats = AvgStats(metrics,True),AvgStats(metrics,False)\n",
    "        \n",
    "    def begin_epoch(self):\n",
    "        self.train_stats.reset()\n",
    "        self.valid_stats.reset()\n",
    "        \n",
    "    def after_loss(self):\n",
    "        stats = self.train_stats if self.in_train else self.valid_stats\n",
    "        with torch.no_grad(): stats.accumulate(self.run)\n",
    "    \n",
    "    def after_epoch(self):\n",
    "        print(self.train_stats)\n",
    "        print(self.valid_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(*get_model(data), loss_func, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = AvgStatsCallback([accuracy])\n",
    "run = Runner(cbs=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.312691640625, tensor(0.9031)]\n",
      "valid: [0.19156544189453126, tensor(0.9436)]\n",
      "train: [0.1461401171875, tensor(0.9557)]\n",
      "valid: [0.1203577880859375, tensor(0.9641)]\n"
     ]
    }
   ],
   "source": [
    "run.fit(2, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1203577880859375, tensor(0.9641))"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss,acc = stats.valid_stats.avg_stats\n",
    "assert acc>0.9\n",
    "loss,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_cbf = partial(AvgStatsCallback, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = Runner(cb_funcs=acc_cbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.11246248046875, tensor(0.9653)]\n",
      "valid: [0.1134654296875, tensor(0.9674)]\n"
     ]
    }
   ],
   "source": [
    "run.fit(1, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using jupyter notebooks means code completion for everything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1134654296875, tensor(0.9674)]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.avg_stats.valid_stats.avg_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HOMEWORK — Understand Callbacks/Annealing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid = get_data()\n",
    "train_ds, valid_ds = Dataset(X_train, y_train), Dataset(X_valid, y_valid)\n",
    "nh, bs = 50, 512\n",
    "c = y_train.max().item() + 1\n",
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch(*get_dls(train_ds, valid_ds, bs), c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner(model_func, loss_func, data):\n",
    "    return Learner(*model_func(data), loss_func, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_func(lr=0.5): \n",
    "    return partial(get_model, lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define two new callbacks: the Recorder to save track of the loss and our scheduled learning rate, and a ParamScheduler that can schedule any hyperparameter as long as it's registered in the state_dict of the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recorder(Callback):\n",
    "    def begin_fit(self): self.lrs,self.losses = [],[]\n",
    "\n",
    "    def after_batch(self):\n",
    "        if not self.in_train: return\n",
    "        self.lrs.append(self.opt.param_groups[-1]['lr'])\n",
    "        self.losses.append(self.loss.detach().cpu())        \n",
    "\n",
    "    def plot_lr  (self): plt.plot(self.lrs)\n",
    "    def plot_loss(self): plt.plot(self.losses)\n",
    "\n",
    "class ParamScheduler(Callback):\n",
    "    _order=1\n",
    "    def __init__(self, pname, sched_func): self.pname,self.sched_func = pname,sched_func\n",
    "\n",
    "    def set_param(self):\n",
    "        for pg in self.opt.param_groups:\n",
    "            pg[self.pname] = self.sched_func(self.n_epochs/self.epochs)\n",
    "            \n",
    "    def begin_batch(self): \n",
    "        if self.in_train: self.set_param()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a simple linear schedule going from start to end. It returns a function that takes a pos argument (going from 0 to 1) such that this function goes from start (at pos=0) to end (at pos=1) in a linear fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sched_lin(start, end):\n",
    "    def _inner(start, end, pos): return start + pos*(end-start)\n",
    "    return partial(_inner, start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can refactor this with a decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annealer(f):\n",
    "    def _inner(start, end): \n",
    "        return partial(f, start, end)\n",
    "    return _inner\n",
    "\n",
    "@annealer\n",
    "def sched_lin(start, end, pos): \n",
    "    return start + pos*(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = sched_lin(1,2)\n",
    "f(0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here are other scheduler functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "@annealer\n",
    "def sched_cos(start, end, pos): return start + (1 + math.cos(math.pi*(1-pos))) * (end-start) / 2\n",
    "@annealer\n",
    "def sched_no(start, end, pos):  return start\n",
    "@annealer\n",
    "def sched_exp(start, end, pos): return start * (end/start) ** pos\n",
    "\n",
    "def cos_1cycle_anneal(start, high, end):\n",
    "    return [sched_cos(start, high), sched_cos(high, end)]\n",
    "\n",
    "#This monkey-patch is there to be able to plot tensors\n",
    "torch.Tensor.ndim = property(lambda x: len(x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "annealings = \"NO LINEAR COS EXP\".split()\n",
    "\n",
    "a = torch.arange(0, 100)\n",
    "p = torch.linspace(0.01,1,100)\n",
    "\n",
    "fns = [sched_no, sched_lin, sched_cos, sched_exp]\n",
    "for fn, t in zip(fns, annealings):\n",
    "    f = fn(2, 1e-2)\n",
    "    plt.plot(a, [f(o) for o in p], label=t)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, we'll often want to combine different schedulers, the following function does that: it uses scheds[i] for pcts[i] of the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_scheds(pcts, scheds):\n",
    "    assert sum(pcts) == 1.\n",
    "    pcts = tensor([0] + listify(pcts))\n",
    "    assert torch.all(pcts >= 0)\n",
    "    pcts = torch.cumsum(pcts, 0)\n",
    "    def _inner(pos):\n",
    "        idx = (pos >= pcts).nonzero().max()\n",
    "        actual_pos = (pos-pcts[idx]) / (pcts[idx+1]-pcts[idx])\n",
    "        return scheds[idx](actual_pos)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example: use 30% of the budget to go from 0.3 to 0.6 following a cosine, then the last 70% of the budget to go from 0.6 to 0.2, still following a cosine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched = combine_scheds([0.3, 0.7], [sched_cos(0.3, 0.6), sched_cos(0.6, 0.2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f75dc627668>]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(a, [sched(o) for o in p])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use it for training quite easily..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbfs = [Recorder,\n",
    "        partial(AvgStatsCallback,accuracy),\n",
    "        partial(ParamScheduler, 'lr', sched)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner(get_model_func(0.3), loss_func, data)\n",
    "run = Runner(cb_funcs=cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.7859915625, tensor(0.7830)]\n",
      "valid: [0.31159970703125, tensor(0.9150)]\n",
      "train: [0.30072205078125, tensor(0.9120)]\n",
      "valid: [0.240205126953125, tensor(0.9323)]\n",
      "train: [0.23519677734375, tensor(0.9326)]\n",
      "valid: [0.20930859375, tensor(0.9408)]\n"
     ]
    }
   ],
   "source": [
    "run.fit(3, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... then check with our recorder if the learning rate followed the right schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.recorder.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
