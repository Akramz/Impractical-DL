{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapping up our CNN\n",
    "\n",
    "First of all, don't worry: this is meant to take a while!\n",
    "\n",
    "Also we cover software engineering because we think that data scientists should be good software engineers.\n",
    "\n",
    "Today we're going to start to move from a minimal training loop to something that is SoTA on ImageNet, things we'll cover:\n",
    "\n",
    "- Cuda\n",
    "- Convolutions\n",
    "- Hooks\n",
    "- Normalization\n",
    "- Transforms\n",
    "- Data Blocks\n",
    "- Label Smoothing\n",
    "- Optimization\n",
    "- Weight Decay\n",
    "- Skip Connection Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks\n",
    "\n",
    "### Callbacks as GUI events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(o):\n",
    "    print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = widgets.Button(description='Click Me')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9a6988d36845c0b9317e6cea9fd4b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Click Me', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.on_click(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meaning, when a click event occurs, **callback** to the function f."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Your Own Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slow_calculation():\n",
    "    res = 0\n",
    "    for i in range(5):\n",
    "        res += i*i\n",
    "        sleep(1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_calculation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine yourself training a deep learning model, you really want to know how it's going. We simulated slow loops by writing `slow_calculation()` and now we're going to inject a call back to check how it's doing while running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slow_calculation(cb=None):\n",
    "    res = 0\n",
    "    for i in range(5):\n",
    "        res += i*i\n",
    "        sleep(1)\n",
    "        if cb:\n",
    "            cb(i)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_progress(epoch):\n",
    "    print(f\"Awesome! We've finished epoch {epoch}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Awesome! We've finished epoch 0!\n",
      "Awesome! We've finished epoch 1!\n",
      "Awesome! We've finished epoch 2!\n",
      "Awesome! We've finished epoch 3!\n",
      "Awesome! We've finished epoch 4!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_calculation(show_progress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lambdas & Partials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Awesome! We've finished epoch 0!\n",
      "Awesome! We've finished epoch 1!\n",
      "Awesome! We've finished epoch 2!\n",
      "Awesome! We've finished epoch 3!\n",
      "Awesome! We've finished epoch 4!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_calculation(lambda epoch: print(f\"Awesome! We've finished epoch {epoch}!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_progress(exclamation, epoch):\n",
    "    print(f\"{exclamation} We've finished epoch {epoch}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK I guess We've finished epoch 0!\n",
      "OK I guess We've finished epoch 1!\n",
      "OK I guess We've finished epoch 2!\n",
      "OK I guess We've finished epoch 3!\n",
      "OK I guess We've finished epoch 4!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_calculation(lambda epoch: show_progress(\"OK I guess\", epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_show_progress(exclamation):\n",
    "    _inner = lambda epoch: print(f\"{exclamation}! We've finished epoch {epoch}!\")\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice! We've finished epoch 0!\n",
      "Nice! We've finished epoch 1!\n",
      "Nice! We've finished epoch 2!\n",
      "Nice! We've finished epoch 3!\n",
      "Nice! We've finished epoch 4!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_calculation(make_show_progress(\"Nice\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might see it done like this instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_show_progress(exclamation):\n",
    "    def _inner(epoch):\n",
    "        print(f\"{exclamation}! We've finished epoch {epoch}!\")\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice! We've finished epoch 0!\n",
      "Nice! We've finished epoch 1!\n",
      "Nice! We've finished epoch 2!\n",
      "Nice! We've finished epoch 3!\n",
      "Nice! We've finished epoch 4!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_calculation(make_show_progress(\"Nice\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazing! We've finished epoch 0!\n",
      "Amazing! We've finished epoch 1!\n",
      "Amazing! We've finished epoch 2!\n",
      "Amazing! We've finished epoch 3!\n",
      "Amazing! We've finished epoch 4!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_calculation(make_show_progress(\"Amazing\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this feature is used soo much, python has `partials`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK I guess We've finished epoch 0!\n",
      "OK I guess We've finished epoch 1!\n",
      "OK I guess We've finished epoch 2!\n",
      "OK I guess We've finished epoch 3!\n",
      "OK I guess We've finished epoch 4!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_calculation(partial(show_progress, \"OK I guess\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = partial(show_progress, \"OK I guess\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK I guess We've finished epoch 0!\n",
      "OK I guess We've finished epoch 1!\n",
      "OK I guess We've finished epoch 2!\n",
      "OK I guess We've finished epoch 3!\n",
      "OK I guess We've finished epoch 4!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_calculation(f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks as Callable Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressShowingCallback():\n",
    "    def __init__(self, exclamation=\"Awesome\"):\n",
    "        self.exclamation = exclamation\n",
    "    \n",
    "    def __call__(self, epoch):\n",
    "        print(f\"{self.exclamation}! We've finished epoch {epoch}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = ProgressShowingCallback(\"Just Super\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just Super! We've finished epoch 0!\n",
      "Just Super! We've finished epoch 1!\n",
      "Just Super! We've finished epoch 2!\n",
      "Just Super! We've finished epoch 3!\n",
      "Just Super! We've finished epoch 4!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_calculation(cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple callback funcs; `*args` and `**kwargs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(*args, **kwargs):\n",
    "    print(f\"args: {args}; kwargs: {kwargs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args: (3, 'a'); kwargs: {'thing1': 'Hello'}\n"
     ]
    }
   ],
   "source": [
    "f(3, 'a', thing1='Hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slow_calculation(cb=None):\n",
    "    res = 0\n",
    "    for i in range(5):\n",
    "        if cb:\n",
    "            cb.before_calc(i)\n",
    "        res += i*i\n",
    "        sleep(1)\n",
    "        if cb:\n",
    "            cb.after_calc(i, val=res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a callback class for the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintStepCallBack():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def before_calc(self, *args, **kwargs):\n",
    "        print(f\"About to start\")\n",
    "    \n",
    "    def after_calc(self, *args, **kwargs):\n",
    "        print(f\"Done step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to start\n",
      "Done step\n",
      "About to start\n",
      "Done step\n",
      "About to start\n",
      "Done step\n",
      "About to start\n",
      "Done step\n",
      "About to start\n",
      "Done step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_calculation(PrintStepCallBack())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous example we didn't get an error because we used `*args` and `**kwargs`, effectively ignoring the passed parameters.\n",
    "\n",
    "Let's now use them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintStatusCallBack():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def before_calc(self, epoch, **kwargs):\n",
    "        print(f\"About to start: {epoch}\")\n",
    "    \n",
    "    def after_calc(self, epoch, val, **kwargs):\n",
    "        print(f\"Done step {epoch}: {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to start: 0\n",
      "Done step 0: 0\n",
      "About to start: 1\n",
      "Done step 1: 1\n",
      "About to start: 2\n",
      "Done step 2: 5\n",
      "About to start: 3\n",
      "Done step 3: 14\n",
      "About to start: 4\n",
      "Done step 4: 30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_calculation(PrintStatusCallBack())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`**kwargs` are kept because we might add other parameters in the future and we don't want to break if the user added non-existing parameters, it makes the class more resilient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slow_calculation(cb=None):\n",
    "    res = 0\n",
    "    for i in range(5):\n",
    "        if cb and hasattr(cb, \"before_calc\"):\n",
    "            cb.before_calc(i)\n",
    "        res += i*i\n",
    "        sleep(1)\n",
    "        if cb and hasattr(cb, \"after_calc\"):\n",
    "            if cb.after_calc(i, val=res):\n",
    "                print(\"Stopping early\")\n",
    "                break\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintAfterCallBack():\n",
    "    def after_calc(self, epoch, val, **kwargs):\n",
    "        print(f\"Done step {epoch}: {val}\")\n",
    "        if val > 10:\n",
    "            return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done step 0: 0\n",
      "Done step 1: 1\n",
      "Done step 2: 5\n",
      "Done step 3: 14\n",
      "Stopping early\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_calculation(PrintAfterCallBack())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to alter the calculation itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlowCalculator():\n",
    "    def __init__(self, cb=None):\n",
    "        self.cb = cb\n",
    "        self.res = 0\n",
    "    \n",
    "    def callback(self, cb_name, *args):\n",
    "        if not self.cb:\n",
    "            return\n",
    "        cb = getattr(self.cb, cb_name, None)\n",
    "        if cb:\n",
    "            return cb(self, *args)\n",
    "    \n",
    "    def calc(self):\n",
    "        for i in range(5):\n",
    "            self.callback('before_calc', i)\n",
    "            self.res += i*i\n",
    "            sleep(1)\n",
    "            if self.callback('after_calc', i):\n",
    "                print(\"Stopping Early\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifyingCallBack():\n",
    "    def after_calc(self, calc, epoch):\n",
    "        print(f\"After epoch {epoch}: {calc.res}\")\n",
    "        if calc.res > 10:\n",
    "            return True\n",
    "        if calc.res < 3:\n",
    "            calc.res = calc.res*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculator = SlowCalculator(ModifyingCallBack())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 0: 0\n",
      "After epoch 1: 1\n",
      "After epoch 2: 6\n",
      "After epoch 3: 15\n",
      "Stopping Early\n"
     ]
    }
   ],
   "source": [
    "calculator.calc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This represent the extend of our callback functionalities that we use in FastAI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `__dunder__` thingies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SloppyAdder():\n",
    "    def __init__(self, o):\n",
    "        self.o = o\n",
    "    \n",
    "    def __add__(self, b):\n",
    "        return SloppyAdder(self.o + b.o + 0.01)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self.o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.01"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = SloppyAdder(1)\n",
    "b = SloppyAdder(2)\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Special Methods I should know:\n",
    "\n",
    "- [x] __getitem__\n",
    "- [ ] __getattr__\n",
    "- [ ] __setattr__\n",
    "- [ ] __del__\n",
    "- [x] __init__\n",
    "- [ ] __new__\n",
    "- [ ] __enter__\n",
    "- [ ] __exit__\n",
    "- [x] __len__\n",
    "- [x] __repr__\n",
    "- [ ] __str__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Browsing Source Code\n",
    "\n",
    "Learn to do these things in our editor of choice:\n",
    "\n",
    "- [ ] Jump to tag/symbol by with (with completion)\n",
    "    - Symbol: class/fucntion/...\n",
    "- [ ] Jump to current tag\n",
    "    - By clicking on the tag\n",
    "- [ ] Jump to library tags\n",
    "- [ ] Go back\n",
    "    - To the place you were working in (in the file)\n",
    "- [ ] Search\n",
    "- [ ] Outlining/Folding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance & Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance\n",
    "\n",
    "Variance is the average of how far each data point is from the mean $\\mu$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.Tensor([1., 2., 4., 18.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.2500)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = t.mean(); m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t-m).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't do that because all of the negative/positive differences cancel-out, so we can fix that in one of two ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(47.1875)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t-m).pow(2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **mean absolute deviation**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.8750)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or..\n",
    "(t-m).abs().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's undo the squaring that happened for the first solution, we present the **standard deviation**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.8693)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t-m).pow(2).mean().sqrt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "they're still different, why?\n",
    "\n",
    "Because of the squaring mechanism, standard deviation is more sensitive to outliers.\n",
    "\n",
    "Here's a useful thing to note about variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(47.1875), tensor(47.1875))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t-m).pow(2).mean(), (t*t).mean() - (m*m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or:\n",
    "\n",
    "$$Var(X)=\\frac{1}{m}\\sum_{i=1}^{m}x_{i}^{2}-\\mu^2=E[X^2]-E[X]^2$$\n",
    "\n",
    "The important thing is that this formula is much more easier to work with. In particular, you only have to track two things:\n",
    "\n",
    "1. The sum of the data\n",
    "2. The sum of squares of the data\n",
    "\n",
    "Whereas in the original formula you have to go through all of the data twice, once to calculate the mean & once to calculate the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariance & Correlation \n",
    "\n",
    "Here's how wikipedia defines covariance:\n",
    "\n",
    "$$Cov(X,Y)=E[(X-E[X])(Y-E[Y])]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  2.,  4., 18.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see that in code, So now we need two vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `u` is twice as `t` plus a little bit of randomness\n",
    "u = t * 2 \n",
    "u += torch.randn_like(t)/10+0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fc43dfd5dd8>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(t, u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 55.2775,  36.6961,  10.0670, 277.7424])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod = (t-t.mean())*(u-u.mean())\n",
    "prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(94.9458)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the previous average with the next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.randn_like(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fc43df6f668>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(t, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.2505,  1.3192, -2.5904, -0.3675])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod = (t-t.mean())*(v-v.mean())\n",
    "prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6530)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covariance tells you how random variables vary jointly, you can also calculate it as follows:\n",
    "\n",
    "$$Cov(X,Y)=E[XY]-E[X]E[Y]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(94.9457)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov = (t*u).mean() - (t.mean()*u.mean())\n",
    "cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, here is the pearson correlation coefficient:\n",
    "\n",
    "$$p_{X,Y}=\\frac{Cov(X,Y)}{\\sigma_{X}\\sigma_{Y}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7500)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov / (t.std() * u.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just a scaled version so that the output is $\\in [-1,1]$.\n",
    "\n",
    "Remember that Covariance and its pearson coefficient describe **linear** variations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax\n",
    "\n",
    "Here's our final `logsoftmax` definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1, keepdim=True).log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is:\n",
    "\n",
    "$$logsoftmax(x)_i=x_i - log\\sum_{j}e^{x_j}$$\n",
    "\n",
    "And our cross entropy loss is:\n",
    "\n",
    "$$-log(p_i)$$\n",
    "\n",
    "A big problem with softmax is that it **must** pick something, so even if the activation values of the last layer are negative (signaling the absence of all classes from an example image) the softmax function will force a probability distribution that sum up to one so that a class can be picked.\n",
    "\n",
    "Another problem that happens is when you have multiple classes present in the image, in this case even the present classes will get minimized by the softmax function in favor of the class associated with the highest activation to be picked.\n",
    "\n",
    "Meaning, softmax is terrible except if you definately know that, per image, you have only one and no more or less than one \"class\" present in the image.\n",
    "\n",
    "If your not sure, use this:\n",
    "\n",
    "$$S(x)=\\frac{e^x}{1+{e^x}}$$\n",
    "\n",
    "And because, for the most part, you won't be sure, **don't use softmax**. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early Stopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better callback cancelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import datasets\n",
    "from torch import tensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gzip, pickle\n",
    "from torch import optim\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(MNIST_URL = 'http://deeplearning.net/data/mnist/mnist.pkl'):\n",
    "    path = datasets.download_data(MNIST_URL, ext='.gz')\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        ((X_train, y_train), (X_val, y_val), _) = pickle.load(f, encoding='latin-1')\n",
    "    return map(tensor, (X_train, y_train, X_val, y_val))\n",
    "\n",
    "def normalize(x, m, s):\n",
    "    return (x-m)/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds = Dataset(X_train, y_train), Dataset(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh, bs = 50, 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = y_train.max().item() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
    "    \"\"\"Returns the dataloaders for both the training and validation sets\"\"\"\n",
    "    return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n",
    "            DataLoader(valid_ds, batch_size=bs*2, **kwargs))\n",
    "\n",
    "\n",
    "class DataBunch():\n",
    "    def __init__(self, train_dl, val_dl, c=None):\n",
    "        self.train_dl, self.val_dl, self.c = train_dl, val_dl, c\n",
    "    \n",
    "    @property\n",
    "    def train_ds(self):\n",
    "        return self.train_dl.dataset\n",
    "    \n",
    "    @property\n",
    "    def valid_ds(self):\n",
    "        return self.val_dl.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch(*get_dls(train_ds, val_ds, bs), c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callback():\n",
    "    _order=0\n",
    "    def set_runner(self, run): self.run=run\n",
    "    def __getattr__(self, k): return getattr(self.run, k)\n",
    "    @property\n",
    "    def name(self):\n",
    "        name = re.sub(r'Callback$', '', self.__class__.__name__)\n",
    "        return camel2snake(name or 'callback')\n",
    "    \n",
    "    def __call__(self, cb_name):\n",
    "        f = getattr(self, cb_name, None)\n",
    "        if f and f():\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "class TrainEvalCallback(Callback):\n",
    "    def begin_fit(self):\n",
    "        self.run.n_epochs=0.\n",
    "        self.run.n_iter=0\n",
    "    \n",
    "    def after_batch(self):\n",
    "        if not self.in_train: return\n",
    "        self.run.n_epochs += 1./self.iters\n",
    "        self.run.n_iter   += 1\n",
    "        \n",
    "    def begin_epoch(self):\n",
    "        self.run.n_epochs=self.epoch\n",
    "        self.model.train()\n",
    "        self.run.in_train=True\n",
    "\n",
    "    def begin_validate(self):\n",
    "        self.model.eval()\n",
    "        self.run.in_train=False\n",
    "        \n",
    "class CancelTrainException(Exception):\n",
    "    pass\n",
    "class CancelEpochException(Exception):\n",
    "    pass\n",
    "class CancelBatchException(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runner():\n",
    "    def __init__(self, cbs=None, cb_funcs=None):\n",
    "        cbs = listify(cbs)\n",
    "        for cbf in listify(cb_funcs):\n",
    "            cb = cbf()\n",
    "            setattr(self, cb.name, cb)\n",
    "            cbs.append(cb)\n",
    "        self.stop,self.cbs = False,[TrainEvalCallback()]+cbs\n",
    "\n",
    "    @property\n",
    "    def opt(self):       return self.learn.opt\n",
    "    @property\n",
    "    def model(self):     return self.learn.model\n",
    "    @property\n",
    "    def loss_func(self): return self.learn.loss_func\n",
    "    @property\n",
    "    def data(self):      return self.learn.data\n",
    "\n",
    "    def one_batch(self, xb, yb):\n",
    "        self.xb,self.yb = xb,yb\n",
    "        if self('begin_batch'): return\n",
    "        self.pred = self.model(self.xb)\n",
    "        if self('after_pred'): return\n",
    "        self.loss = self.loss_func(self.pred, self.yb)\n",
    "        if self('after_loss') or not self.in_train: return\n",
    "        self.loss.backward()\n",
    "        if self('after_backward'): return\n",
    "        self.opt.step()\n",
    "        if self('after_step'): return\n",
    "        self.opt.zero_grad()\n",
    "\n",
    "    def all_batches(self, dl):\n",
    "        self.iters = len(dl)\n",
    "        for xb,yb in dl:\n",
    "            if self.stop: break\n",
    "            self.one_batch(xb, yb)\n",
    "            self('after_batch')\n",
    "        self.stop=False\n",
    "        \n",
    "    def fit(self, epochs, learn):\n",
    "        self.epochs,self.learn = epochs,learn\n",
    "\n",
    "        try:\n",
    "            for cb in self.cbs: cb.set_runner(self)\n",
    "            if self('begin_fit'): return\n",
    "            for epoch in range(epochs):\n",
    "                self.epoch = epoch\n",
    "                if not self('begin_epoch'): self.all_batches(self.data.train_dl)\n",
    "\n",
    "                with torch.no_grad(): \n",
    "                    if not self('begin_validate'): self.all_batches(self.data.val_dl)\n",
    "                if self('after_epoch'): break\n",
    "\n",
    "        except CancelTrainException:\n",
    "            self('after_cancel_train')\n",
    "        finally:\n",
    "            self('after_fit')\n",
    "            self.learn = None\n",
    "\n",
    "    def __call__(self, cb_name):\n",
    "        for cb in sorted(self.cbs, key=lambda x: x._order):\n",
    "            f = getattr(cb, cb_name, None)\n",
    "            if f and f(): return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learner(model_func, loss_func, data):\n",
    "    return Learner(*model_func(data), loss_func, data)\n",
    "\n",
    "def get_model(data, lr=0.5, nh=50):\n",
    "    n = data.train_ds.x.shape[1]\n",
    "    model = nn.Sequential(nn.Linear(n, nh), nn.ReLU(), nn.Linear(nh, data.c))\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "class Learner():\n",
    "    def __init__(self, model, opt, loss_func, data):\n",
    "        self.model, self.opt, self.loss_func, self.data = model, opt, loss_func, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner(get_model, loss_func, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "\n",
    "def listify(o):\n",
    "    if o is None: return []\n",
    "    if isinstance(o, list): return o\n",
    "    if isinstance(o, str): return [o]\n",
    "    if isinstance(o, Iterable): return list(o)\n",
    "    return [o]\n",
    "\n",
    "class TestCallBack(Callback):\n",
    "    _order=1\n",
    "    \n",
    "    def after_step(self):\n",
    "        print(self.n_iter)\n",
    "        if self.n_iter >= 10:\n",
    "            raise CancelTrainException()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "_camel_re1 = re.compile('(.)([A-Z][a-z]+)')\n",
    "_camel_re2 = re.compile('([a-z0-9])([A-Z])')\n",
    "def camel2snake(name):\n",
    "    s1 = re.sub(_camel_re1, r'\\1_\\2', name)\n",
    "    return re.sub(_camel_re2, r'\\1_\\2', s1).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = Runner(cb_funcs=TestCallBack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "run.fit(3, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Callbacks\n",
    "\n",
    "### LR Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR_Find(Callback):\n",
    "    _order = 1\n",
    "    def __init__(self, max_iter=100, min_lr=1e-6, max_lr=10):\n",
    "        self.max_iter, self.min_lr, self.max_lr = max_iter, min_lr, max_lr\n",
    "        self.best_loss = 1e9\n",
    "    \n",
    "    def begin_batch(self):\n",
    "        if not self.in_train:\n",
    "            return\n",
    "        pos = self.n_iter/self.max_iter\n",
    "        lr = self.min_lr * (self.max_lr/self.min_lr) ** pos\n",
    "        for pg in self.opt.param_groups:\n",
    "            pg['lr'] = lr\n",
    "    \n",
    "    def after_step(self):\n",
    "        if self.n_iter >= self.max_iter or self.loss > self.best_loss * 10:\n",
    "            raise CancelTrainException()\n",
    "        if self.loss < self.best_loss:\n",
    "            self.best_loss = self.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
